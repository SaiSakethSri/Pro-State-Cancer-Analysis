##  KNN Classification

## Case Study -
### Data : Prostate Cancer data

## One of the leading Cancer Research institute is working on a research project to 
## understand the structural properties of various Prostate Cancer tumors and make some 
## conclusion to distinguish between Malignant and Benign Tumors based on the structural differences
## The main objective is to use these properties to classify the tumors into correct categories 
## (Malignant and Benign).



### Dependent variable - Diagnosis_result (Type : Malignant (M) or Benign (B) cancer)
### Independent variables - All other




os.chdir("D:\Data Science Training\Data")

import pandas as pd

data = pd.read_csv("Prostate_Cancer.csv")


data.info()


data.diagnosis_result.value_counts()

## Missing data Handling

pd.isna(data)

pd.isna(data.diagnosis_result)

pd.isna(data.diagnosis_result).value_counts()




#### 1.2  Categorical Data Handling 

data.info()

object_cols = list(data.select_dtypes(include=['category','object']))

object_cols

data.diagnosis_result.value_counts()


## Using Label Encoder



from sklearn.preprocessing import LabelEncoder


le = LabelEncoder()


label = le.fit_transform(data.diagnosis_result)

label

data = data.join(pd.DataFrame({'label':label}))

data.drop('diagnosis_result',axis=1,inplace=True)


data.info()



#### 1.3 Splitting data into Training and Test Data Sets




from sklearn.model_selection import train_test_split


data.info()

data_X = data.iloc[:,[0,1,2,3,4,5,6,7,8]]
data_y = data[:]['label']


X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=100)

X_train.info()

y_train

X_test.info()

y_test





## Feature Selection - Checking Correlation to get perfect set of indipendent variables


cr = data.corr()

cr['label']

sns.heatmap(cr,annot=True,cmap="coolwarm")


## Conclusion - Selected independent variables : radius,perimeter,area,smoothness,compactness,symmetry
## building linear Model


X_train.info()

X_train.drop(['id','texture','fractal_dimension'],axis=1,inplace=True)

X_train.info()

X_test.info()

X_test.drop(['id','texture','fractal_dimension'],axis=1,inplace=True)

X_test.info()


## Check for Classification boundries


import matplotlib.cm as cm
colors = cm.rainbow(y_train*500)


fig,axes = plt.subplots(figsize=(10,10))
axes.scatter(X_train.perimeter,X_train.compactness,c=colors,alpha=0.7,s=1000)
    


## Build the Model

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=8)


# Train the model using the training sets

knn.fit(X_train,y_train)



## Predicting death_rate for test dataset using model

y_pred = knn.predict(X_test)

res = pd.DataFrame({'y_act':y_test,'y_pred':y_pred})




## Analyze your model performance visually


import matplotlib.cm as cm
colors1 = cm.rainbow(y_test*500)
colors2= cm.rainbow(y_pred*500)


fig,axes = plt.subplots(figsize=(10,10))
axes.scatter(X_test.perimeter,X_test.compactness,c=colors1,s=600,edgecolor='black')
axes.scatter(X_test.perimeter,X_test.compactness,c=colors2,s=300)


## Model Evaluation - Confusion Matrix

from sklearn.metrics import confusion_matrix


cnf_matrix = confusion_matrix(y_test, y_pred)



print(cnf_matrix)


acc = (cnf_matrix[0,0]+cnf_matrix[1,1])/(cnf_matrix[0,0]+cnf_matrix[0,1]+cnf_matrix[1,0]+cnf_matrix[1,1])






